{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7728a37",
   "metadata": {},
   "source": [
    "# Diffusion Model Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7590036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66095b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import diffusers\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "model_id = \"google/ddpm-bedroom-256\" # \"google/ddpm-celebahq-256\"\n",
    "model = diffusers.UNet2DModel.from_pretrained(model_id)\n",
    "ddpm_scheduler = diffusers.DDPMScheduler.from_pretrained(model_id)\n",
    "ddpm_scheduler.set_timesteps(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4470aac2",
   "metadata": {},
   "source": [
    "# Denoising Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4205a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input prepraration\n",
    "image_size = model.config.sample_size # get image size\n",
    "noise = torch.randn((1, 3, image_size, image_size)) # sample random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generation\n",
    "current = noise\n",
    "history = [noise]\n",
    "for i, t in enumerate(ddpm_scheduler.timesteps):\n",
    "    with torch.no_grad():\n",
    "        predicted_noise = model(current, t).sample\n",
    "        current = ddpm_scheduler.step(predicted_noise, t, current).prev_sample\n",
    "        show_table([[tensor_as_html(history[-1]), tensor_as_html(predicted_noise), tensor_as_html(current)], [\"Image\", \"Predicted Noise\", \"Image - Predicted Noise\"], [\"\", f\"{i + 1}/50\", \"\"]])\n",
    "        history.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f33d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images\n",
    "show_images(*history[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9064c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image\n",
    "os.makedirs(\"../output\", exist_ok=True)\n",
    "tensor_as_image(current).save(\"../output/output.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5afea02",
   "metadata": {},
   "source": [
    "# Forward and Backward Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0be6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward process\n",
    "noised_image = ddpm_scheduler.add_noise(current, noise, ddpm_scheduler.timesteps[30])\n",
    "tensor_as_image(noised_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45d2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward process\n",
    "current = noised_image\n",
    "for t in tqdm(ddpm_scheduler.timesteps[30:]):\n",
    "    with torch.no_grad():\n",
    "        predicted_noise = model(current, t).sample\n",
    "        current = ddpm_scheduler.step(predicted_noise, t, current).prev_sample\n",
    "        show_images(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a32a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare images\n",
    "show_images(history[-1], current, history[-1] - current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f12143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create forward / backward process image\n",
    "image = current # image_as_tensor(Image.open(\"../output/ddpm_9.png\"))\n",
    "\n",
    "# setup output image\n",
    "output = Image.new(\"RGB\", (image_size * 50, image_size * 50), (255, 255, 255))\n",
    "output.paste(tensor_as_image(image), (0, 0))\n",
    "\n",
    "# output generation\n",
    "with tqdm(total=sum(range(1, 51))) as tqdm_bar:\n",
    "    for i in reversed(range(50)):\n",
    "        current = ddpm_scheduler.add_noise(image, noise, ddpm_scheduler.timesteps[i])\n",
    "        output.paste(tensor_as_image(current), (0, image_size * (50 - i)))\n",
    "        for j, t in enumerate(ddpm_scheduler.timesteps[i:]):\n",
    "            with torch.no_grad():\n",
    "                predicted_noise = model(current, t).sample\n",
    "                current = ddpm_scheduler.step(predicted_noise, t, current).prev_sample\n",
    "                output.paste(tensor_as_image(current), (image_size * (j + 1), image_size * (50 - i)))\n",
    "            tqdm_bar.update(1)\n",
    "\n",
    "# save output image\n",
    "output.save(\"output/process.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b932a555",
   "metadata": {},
   "source": [
    "# DDIM with Similar Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84085697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "ddim_scheduler = diffusers.DDIMScheduler.from_pretrained(model_id)\n",
    "ddim_scheduler.set_timesteps(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input\n",
    "noise = torch.randn((1, 3, image_size, image_size)) # sample random noise\n",
    "noises = [noise.clone() for _ in range(2)] # duplicate noise\n",
    "noises[1][:,:,50:100,50:100] = torch.randn((1, 3, 50, 50)) # modify second noise\n",
    "show_images(*noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8709e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "for i in range(10):\n",
    "    show_images(noises[i % 2])\n",
    "    sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a5625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generation\n",
    "images = list()\n",
    "for current in noises:\n",
    "    for t in tqdm(ddim_scheduler.timesteps):\n",
    "        with torch.no_grad():\n",
    "            predicted_noise = model(current, t).sample\n",
    "            current = ddim_scheduler.step(predicted_noise, t, current).prev_sample\n",
    "    images.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597dc29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show output\n",
    "show_images(*images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d8c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save input and output\n",
    "for i in range(len(noises)):\n",
    "    tensor_as_image(noises[i]).save(f\"../output/similar_ddim_noise_{i}.png\")\n",
    "    tensor_as_image(images[i]).save(f\"../output/similar_ddim_image_{i}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a437e",
   "metadata": {},
   "source": [
    "# DDIM Accelerated Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdcbe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generation\n",
    "current = noise\n",
    "for t in tqdm(ddim_scheduler.timesteps):\n",
    "    with torch.no_grad():\n",
    "        predicted_noise = model(current, t).sample\n",
    "        current = ddim_scheduler.step(predicted_noise, t, current).prev_sample\n",
    "        show_images(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbf3eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddim_scheduler.set_timesteps(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb11ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generation\n",
    "second = noise\n",
    "for t in tqdm(ddim_scheduler.timesteps):\n",
    "    with torch.no_grad():\n",
    "        predicted_noise = model(second, t).sample\n",
    "        second = ddim_scheduler.step(predicted_noise, t, second).prev_sample\n",
    "        show_images(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ebddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(current, second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde46b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
