{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7728a37",
   "metadata": {},
   "source": [
    "# Diffusion Model Project\n",
    "\n",
    "This notebook contains a basic animation of the denoising diffusion process and a comparison of different timestep values.\n",
    "\n",
    "What you can change in the `src/config.yaml`:\n",
    "- You can select the model (and dataset) used by editing the `model` attribute\n",
    "- You can select the number of generation time steps by editing the `model.timesteps` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7590036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions\n",
    "import diffusers\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "model_id = functions.config(\"model\")\n",
    "model = diffusers.UNet2DModel.from_pretrained(model_id)\n",
    "ddpm_scheduler = diffusers.DDPMScheduler.from_pretrained(model_id)\n",
    "ddpm_scheduler.set_timesteps(functions.config(\"model.timesteps\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4470aac2",
   "metadata": {},
   "source": [
    "## Denoising Animation\n",
    "\n",
    "This part shows a basic animation of the denoising diffusion process.\n",
    "\n",
    "If the generation takes too long, try to decrease the `model.timesteps` attribute in the `src/config.yaml` file. If the generated image look too bad, try to increase the `model.timesteps` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4205a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input prepraration\n",
    "image_size = model.config.sample_size # get image size\n",
    "noise = functions.generate_noise(image_size) # sample random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generation\n",
    "current = noise\n",
    "history = [noise]\n",
    "for i, t in enumerate(ddpm_scheduler.timesteps):\n",
    "    with torch.no_grad():\n",
    "        predicted_noise = model(current, t).sample\n",
    "        current = ddpm_scheduler.step(predicted_noise, t, current).prev_sample\n",
    "        labels = [f\"Image {i + 1}/{functions.config('model.timesteps')}\", \"Predicted Noise\", \"Image - Predicted Noise\"]\n",
    "        functions.show_images(history[-1], predicted_noise, current, labels=labels)\n",
    "        history.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f33d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images\n",
    "functions.show_images(*history[::functions.config('model.timesteps')//5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b859f1",
   "metadata": {},
   "source": [
    "If you want to save the generated image, you can execute the following cell. Consider choosing a reasonable file name to avoid overwriting potentially existing files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9064c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image\n",
    "functions.tensor_as_image(current).save(\"../output/output.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a437e",
   "metadata": {},
   "source": [
    "## DDIM Accelerated Sampling\n",
    "\n",
    "This part compares different numbers of diffusion timesteps. Feel free to adjust the number of timesteps to compare ot to add more values to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04985f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "ddim_scheduler = diffusers.DDIMScheduler.from_pretrained(model_id)\n",
    "timesteps = [10, 50, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdcbe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generation\n",
    "images = [noise for _ in range(len(timesteps))]\n",
    "for i in range(len(timesteps)):\n",
    "    ddim_scheduler.set_timesteps(timesteps[i])\n",
    "    for t in tqdm(ddim_scheduler.timesteps):\n",
    "        with torch.no_grad():\n",
    "            predicted_noise = model(images[i], t).sample\n",
    "            images[i] = ddim_scheduler.step(predicted_noise, t, images[i]).prev_sample\n",
    "            functions.show_images(*images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
