{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe9f338",
   "metadata": {},
   "source": [
    "## DDIM with similar noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85bc3b7",
   "metadata": {},
   "source": [
    "In this notebook, we will conduct experiments where we will use two noise images as input, which differ only slightly or in small areas. Subsequently, we will examine the extent and location of the differences in the generated clear images and attempt to interpret the results.\n",
    "\n",
    "As you will see, we often display images alternately and provide both **heatmaps** and **Euclidean distances** to help you precisely identify the degree and location of image differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ce3a5",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we initialize our model. Note that we have chosen a DDIM scheduler. This is crucial. Unlike Denoising Diffusion Probabilistic Models (DDPM), DDIMs work deterministically, i.e., from one specific full noise image, they will always generate the same clear image. If we used a probabilistic model, a small amount of noise would be added back into the image after every backward step, which would cause the results to vary significantly, even with the same starting point.\n",
    "\n",
    "**Note on performance:** If the image generation process is too slow, you can decrease the number of sampling steps. This will reduce computation time but may also lower the quality of the generated images. To do this, choose a lower value in `ddim_scheduler.set_timesteps(50)` (see code cell 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9bf74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd6639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import diffusers\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12007703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "model_id = \"google/ddpm-bedroom-256\" # \"google/ddpm-celebahq-256\"\n",
    "model = diffusers.UNet2DModel.from_pretrained(model_id)\n",
    "ddim_scheduler = diffusers.DDIMScheduler.from_pretrained(model_id)\n",
    "# time steps for generation process, can be decreased to save computation time, images might be of lower quality\n",
    "ddim_scheduler.set_timesteps(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input prepraration\n",
    "image_size = model.config.sample_size # get image size\n",
    "noise = torch.randn((1, 3, image_size, image_size)) # sample random noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b0ee7",
   "metadata": {},
   "source": [
    "## 1. Experiment\n",
    "\n",
    "In this experiment, we will modify a small patch within a full noise image and then generate two distinct images from it. You can customize the patch's size and position by adjusting the `patch_size`, `patch_position_x`, and `patch_position_y` variables in `/src/config.yml`. As you run the code, pay close attention to the extent and, more importantly, **the location** of the differences in the generated images.\n",
    "\n",
    "We will begin by generating two noise images that vary in a small region; these will subsequently serve as inputs for our decoder, which is the image generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20faa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letting the user choose patchsize and position\n",
    "patch_size, patch_position_x, patch_position_y = user_input_patch()\n",
    "\n",
    "# prepare input\n",
    "noise = torch.randn((1, 3, image_size, image_size)) # sample random noise\n",
    "noises = [noise.clone() for _ in range(2)] # duplicate noise\n",
    "noises[1][:,:,patch_position_y:patch_position_y+patch_size,patch_position_x:patch_position_x+patch_size] = torch.randn((1, 3, patch_size, patch_size)) # change a small patch in one of the full noise pictures\n",
    "euclidean = torch.norm((noises[0]-noises[1])).item() # calculate euclidean distance\n",
    "show_table([[tensor_as_html(noises[0]), tensor_as_html(noises[1]), tensor_as_html(torch.abs(noises[0]-noises[1]).mean(dim=1,keepdim=True).repeat(1,3,1,1))], [\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]])#display images, euclidean, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6a5eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the images alternately\n",
    "from time import sleep\n",
    "for i in range(10):\n",
    "    show_images(noises[i % 2])\n",
    "    sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec30a7",
   "metadata": {},
   "source": [
    "Now, the image generation process is executed. Please examine the outputs closely. You will observe that altering a small patch in the input noise image affects not only that specific patch in the generated image but the entire image. This demonstrates how diffusion models capture long-range dependencies between pixels by learning the probability distributions from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77414b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generation\n",
    "images = list()\n",
    "for current in noises:\n",
    "    for t in tqdm(ddim_scheduler.timesteps):\n",
    "        with torch.no_grad():\n",
    "            predicted_noise = model(current, t).sample\n",
    "            current = ddim_scheduler.step(predicted_noise, t, current).prev_sample\n",
    "    images.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show output\n",
    "euclidean = torch.norm((images[0]-images[1])).item() # calculate euclidean distance\n",
    "show_table([[tensor_as_html(images[0]), tensor_as_html(images[1]), tensor_as_html(torch.abs(images[0]-images[1]).mean(dim=1,keepdim=True).repeat(1,3,1,1))], [\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]])#display images, euclidean, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b57bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save input and output\n",
    "for i in range(len(noises)):\n",
    "    tensor_as_image(noises[i]).save(f\"../output/similar_ddim_noise_{i}.png\")\n",
    "    tensor_as_image(images[i]).save(f\"../output/similar_ddim_image_{i}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8368b2b5",
   "metadata": {},
   "source": [
    "## 2. Experiment\n",
    "\n",
    "In this experiment, we will modify the full noise images such that the mathematical distance between the two input noise images is small. You can control the degree to which the noises differ by adjusting the `noise_scaling_factor` variable in `/src/config.yml`.\n",
    "\n",
    "We will again begin by generating two noise images, but unlike the first experiment, they will differ slightly across the entire image rather than heavily in a small patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4244f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Letting the user choose a scaling factor\n",
    "noise_scaling_factor = user_input_noise_scaling_factor()     \n",
    "\n",
    "# prepare input\n",
    "noise = torch.randn((1, 3, image_size, image_size)) # sample random noise\n",
    "noises = [noise.clone() for _ in range(2)] # duplicate noise\n",
    "noises[1] = ((1-noise_scaling_factor**2)**0.5) * noises[1] + noise_scaling_factor * torch.randn((1, 3, image_size, image_size)) # change one of the full noise pictures by adding newly generated noise scaled down heavily\n",
    "euclidean = torch.norm((noises[0]-noises[1])).item() # calculate euclidean distance\n",
    "show_table([[tensor_as_html(noises[0]), tensor_as_html(noises[1]), tensor_as_html(torch.abs(noises[0]-noises[1]).mean(dim=1,keepdim=True).repeat(1,3,1,1))], [\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]])#display images, euclidean, heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b8880e",
   "metadata": {},
   "source": [
    "Now, the actual image generation is executed. Please examine the outputs closely. As you will see, slightly changing the input noise leads to only small changes in the resulting clear image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generation\n",
    "images = list()\n",
    "for current in noises:\n",
    "    for t in tqdm(ddim_scheduler.timesteps):\n",
    "        with torch.no_grad():\n",
    "            predicted_noise = model(current, t).sample\n",
    "            current = ddim_scheduler.step(predicted_noise, t, current).prev_sample\n",
    "    images.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a68684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show output\n",
    "euclidean = torch.norm((images[0]-images[1])).item() # calculate euclidean distance\n",
    "show_table([[tensor_as_html(images[0]), tensor_as_html(images[1]), tensor_as_html(torch.abs(images[0]-images[1]).mean(dim=1,keepdim=True).repeat(1,3,1,1))], [\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]])#display images, euclidean, heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22247811",
   "metadata": {},
   "source": [
    "Now that you're familiar with the two experiments, you can perform your own by changing the relevant variables in `/src/config.yml`.\n",
    "\n",
    "Some interesting research questions you might explore include:\n",
    "\n",
    "* Is there a correlation between the Euclidean distance of the noise images and that of the clear images?\n",
    "* Is the Euclidean distance of the noise images generally smaller or larger than that of the clear images? Try to explain this based on how the diffusion process works.\n",
    "* Given a similar Euclidean distance of noise images in both experiments, is the result altered more significantly in the patch condition or the full noise condition?\n",
    "* In Experiment 2: How much do you need to change the noise image to obtain substantially different results?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
