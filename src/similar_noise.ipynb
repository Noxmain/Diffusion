{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe9f338",
   "metadata": {},
   "source": [
    "# DDIM with similar noise\n",
    "\n",
    "In this notebook, we will conduct experiments where we will use two noise images as input, which differ only slightly or in small areas. Subsequently, we will examine the extent and location of the differences in the generated clear images and attempt to interpret the results.\n",
    "\n",
    "As you will see, we often display images alternately and provide both **heatmaps** and **Euclidean distances** to help you precisely identify the degree and location of image differences.\n",
    "\n",
    "What you can change in the `src/config.yaml`:\n",
    "- You can select the model (and dataset) used by editing the `model` attribute\n",
    "- You can select the number of generation time steps by editing the `model.timesteps` attribute\n",
    "- You can select the size and position of the noise patch by editing the attributes `patch.size`, `patch.position.x` and `patch.position.y`\n",
    "- You can select the noise scaling factor by editing the `noise.scaling` attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ce3a5",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we initialize our model. Note that we have chosen a DDIM scheduler. This is crucial. Unlike Denoising Diffusion Probabilistic Models (DDPM), DDIMs work deterministically, i.e., from one specific full noise image, they will always generate the same clear image. If we used a probabilistic model, a small amount of noise would be added back into the image after every backward step, which would cause the results to vary significantly, even with the same starting point.\n",
    "\n",
    "**Note on performance:** If the image generation process is too slow, you can decrease the number of sampling steps. This will reduce computation time but may also lower the quality of the generated images. To do this, choose a lower value in `ddim_scheduler.set_timesteps(50)` (see code cell 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9bf74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions\n",
    "import diffusers\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12007703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "model_id = functions.config(\"model\")\n",
    "model = diffusers.UNet2DModel.from_pretrained(model_id)\n",
    "ddim_scheduler = diffusers.DDIMScheduler.from_pretrained(model_id)\n",
    "# time steps for generation process can be decreased in \"src/config.yaml\" to save computation time but images might be of lower quality\n",
    "ddim_scheduler.set_timesteps(functions.config(\"model.timesteps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input prepraration\n",
    "image_size = model.config.sample_size # get image size\n",
    "noise = functions.generate_noise(image_size) # sample random noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b0ee7",
   "metadata": {},
   "source": [
    "## 1. Experiment\n",
    "\n",
    "In this experiment, we will modify a small patch within a full noise image and then generate two distinct images from it. You can customize the patch's size and position by adjusting `patch.size`, `patch.position.x`, and `patch.position.y` in the `src/config.yaml` file. As you run the code, pay close attention to the extent and, more importantly, **the location** of the differences in the generated images.\n",
    "\n",
    "We will begin by generating two noise images that vary in a small region; these will subsequently serve as inputs for our decoder, which is the image generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20faa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# letting the user choose the patch size and position\n",
    "patch_size = functions.config(\"patch.size\")\n",
    "patch_position_x = functions.config(\"patch.position.x\")\n",
    "patch_position_y = functions.config(\"patch.position.y\")\n",
    "\n",
    "# prepare input\n",
    "noise_1 = functions.generate_noise(image_size) # sample random noise\n",
    "noise_2 = noise_1.clone() # duplicate noise\n",
    "noise_patch = functions.generate_noise(patch_size) # sample random noise patch\n",
    "noise_2[:,:,patch_position_y:patch_position_y+patch_size,patch_position_x:patch_position_x+patch_size] = noise_patch # insert noise patch\n",
    "euclidean = torch.norm((noise_1 - noise_2)).item() # calculate euclidean distance\n",
    "difference_map = torch.abs(noise_1 - noise_2).mean(dim=1, keepdim=True).repeat(1,3,1,1) # calculate difference map\n",
    "functions.show_images(noise_1, noise_2, difference_map, labels=[\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]) # display images, euclidean, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6a5eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the images alternately\n",
    "for i in range(10):\n",
    "    functions.show_images([noise_1, noise_2][i % 2])\n",
    "    sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec30a7",
   "metadata": {},
   "source": [
    "Now, the image generation process is executed. Please examine the outputs closely. You will observe that altering a small patch in the input noise image affects not only that specific patch in the generated image but the entire image. This demonstrates how diffusion models capture long-range dependencies between pixels by learning the probability distributions from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77414b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generation\n",
    "images = list()\n",
    "for current in [noise_1, noise_2]:\n",
    "    for t in tqdm(ddim_scheduler.timesteps):\n",
    "        with torch.no_grad():\n",
    "            predicted_noise = model(current, t).sample\n",
    "            current = ddim_scheduler.step(predicted_noise, t, current).prev_sample\n",
    "    images.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show output\n",
    "euclidean = torch.norm((images[0] - images[1])).item() # calculate euclidean distance\n",
    "difference_map = torch.abs(images[0] - images[1]).mean(dim=1, keepdim=True).repeat(1,3,1,1) # calculate difference map\n",
    "functions.show_images(images[0], images[1], difference_map, labels=[\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]) # display images, euclidean, heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59987726",
   "metadata": {},
   "source": [
    "If you want to save the generated images, you can execute the following cell. Consider choosing a reasonable file name to avoid overwriting potentially existing files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b57bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save input and output\n",
    "functions.tensor_as_image(noise_1).save(\"../output/similar_noise_1.png\")\n",
    "functions.tensor_as_image(noise_2).save(\"../output/similar_noise_2.png\")\n",
    "functions.tensor_as_image(images[0]).save(\"../output/similar_image_1.png\")\n",
    "functions.tensor_as_image(images[1]).save(\"../output/similar_image_2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8368b2b5",
   "metadata": {},
   "source": [
    "## 2. Experiment\n",
    "\n",
    "In this experiment, we will modify the full noise images such that the mathematical distance between the two input noise images is small. You can control the degree to which the noises differ by adjusting `noise.scaling` in the `src/config.yaml` file.\n",
    "\n",
    "We will again begin by generating two noise images, but unlike the first experiment, they will differ slightly across the entire image rather than heavily in a small patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4244f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Letting the user choose a scaling factor\n",
    "noise_scaling_factor = functions.config(\"noise.scaling\")\n",
    "\n",
    "# prepare input\n",
    "noise_1 = functions.generate_noise(image_size) # sample random noise\n",
    "noise_2 = ((1 - noise_scaling_factor ** 2) ** 0.5) * noise_1 + noise_scaling_factor * functions.generate_noise(image_size) # change one of the full noise pictures by adding newly generated noise scaled down heavily\n",
    "euclidean = torch.norm((noise_1 - noise_2)).item() # calculate euclidean distance\n",
    "difference_map = torch.abs(noise_1 - noise_2).mean(dim=1, keepdim=True).repeat(1,3,1,1) # calculate difference map\n",
    "functions.show_images(noise_1, noise_2, difference_map, labels=[\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]) # display images, euclidean, heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b8880e",
   "metadata": {},
   "source": [
    "Now, the actual image generation is executed. Please examine the outputs closely. As you will see, slightly changing the input noise leads to only small changes in the resulting clear image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generation\n",
    "images = list()\n",
    "for current in [noise_1, noise_2]:\n",
    "    for t in tqdm(ddim_scheduler.timesteps):\n",
    "        with torch.no_grad():\n",
    "            predicted_noise = model(current, t).sample\n",
    "            current = ddim_scheduler.step(predicted_noise, t, current).prev_sample\n",
    "    images.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a68684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show output\n",
    "euclidean = torch.norm((images[0] - images[1])).item() # calculate euclidean distance\n",
    "difference_map = torch.abs(images[0] - images[1]).mean(dim=1, keepdim=True).repeat(1,3,1,1) # calculate difference map\n",
    "functions.show_images(images[0], images[1], difference_map, labels=[\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]) # display images, euclidean, heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22247811",
   "metadata": {},
   "source": [
    "Now that you're familiar with the two experiments, you can perform your own by changing the relevant variables in `src/config.yaml`.\n",
    "\n",
    "Some interesting research questions you might explore include:\n",
    "\n",
    "* Is there a correlation between the Euclidean distance of the noise images and that of the clear images?\n",
    "* Is the Euclidean distance of the noise images generally smaller or larger than that of the clear images? Try to explain this based on how the diffusion process works.\n",
    "* Given a similar Euclidean distance of noise images in both experiments, is the result altered more significantly in the patch condition or the full noise condition?\n",
    "* In Experiment 2: How much do you need to change the noise image to obtain substantially different results?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
