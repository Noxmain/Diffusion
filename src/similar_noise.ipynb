{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe9f338",
   "metadata": {},
   "source": [
    "## DDIM with similar noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85bc3b7",
   "metadata": {},
   "source": [
    "In this notebook, we will perform some experiments with Denoising Diffusion Implicit Models (DDIM). Unlike Denoising Diffusion Probabilistic Models (DDPM), DDIMs work deterministically, i.e., from one specific full noise image, they will always generate the same clear image. Using a deterministic backward process is essential here. If we used a probabilistic model, a small amount of noise would be added back into the image after every backward step, which would cause the results to vary significantly, even with the same starting point.\n",
    "\n",
    "We will do two experiments:\n",
    "\n",
    "1. **Experiment (Patch condition):** Change a small patch in the full noise image and generate two clear images from it. You can choose the patch size and position yourself.\n",
    "2. **Experiment (Full noise condition):** Modify the full noise images in such a way that the mathematical distance between the two starting noise images is very small. You can control how much the noise is changed by selecting a value for `noise_scaling_factor`.\n",
    "\n",
    "Each experiment demonstrates different effects:\n",
    "\n",
    "1. **Experiment (Patch condition):** Changing a small patch in the full noise image will not only affect that exact patch in the clear image but the entire image. This shows that diffusion models capture dependencies between pixels by learning the probability distributions from the training dataset.\n",
    "2. **Experiment (Full noise condition):** Slightly changing the noise leads to only small changes in the resulting clear image.\n",
    "\n",
    "As you will see, the Euclidean distance and a heatmap are displayed after each experiment to give you an objective and visual measure of where and how the images differ. Feel free to try out different values in both experiments. Some interesting research questions you might explore include:\n",
    "\n",
    "* Is there a correlation between the Euclidean distance of the noise images and that of the clear images?\n",
    "* Is the Euclidean distance of the noise images generally smaller or larger than that of the clear images? Try to explain the answer based on how the diffusion process works.\n",
    "* Given a similar Euclidean distance of noise images in both experiments, is the result changed more strongly in the patch condition or the full noise condition?\n",
    "* In Experiment 2: How much do you need to change the noise image to get substantially different results?\n",
    "\n",
    "**Note on performance issues:** If the image generation process takes too long, you can decrease the number of steps. This will save computation time but also reduce the quality of the results. To do that, choose a lower value in `ddim_scheduler.set_timesteps(50)` (see code cell 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ce3a5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9bf74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd6639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import diffusers\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12007703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "model_id = \"google/ddpm-bedroom-256\" # \"google/ddpm-celebahq-256\"\n",
    "model = diffusers.UNet2DModel.from_pretrained(model_id)\n",
    "ddim_scheduler = diffusers.DDIMScheduler.from_pretrained(model_id)\n",
    "# time steps for generation process, can be decreased to save computation time, images might be of lower quality\n",
    "ddim_scheduler.set_timesteps(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input prepraration\n",
    "image_size = model.config.sample_size # get image size\n",
    "noise = torch.randn((1, 3, image_size, image_size)) # sample random noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b0ee7",
   "metadata": {},
   "source": [
    "## 1. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20faa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letting the user choose patchsize and position\n",
    "patch_size, patch_position_x, patch_position_y = user_input_patch()\n",
    "\n",
    "# prepare input\n",
    "noise = torch.randn((1, 3, image_size, image_size)) # sample random noise\n",
    "noises = [noise.clone() for _ in range(2)] # duplicate noise\n",
    "noises[1][:,:,patch_position_y:patch_position_y+patch_size,patch_position_x:patch_position_x+patch_size] = torch.randn((1, 3, patch_size, patch_size)) # change a small patch in one of the full noise pictures\n",
    "euclidean = torch.norm((noises[0]-noises[1])).item() # calculate euclidean distance\n",
    "show_table([[tensor_as_html(noises[0]), tensor_as_html(noises[1]), tensor_as_html(torch.abs(noises[0]-noises[1]).mean(dim=1,keepdim=True).repeat(1,3,1,1))], [\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]])#display images, euclidean, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6a5eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the images alternately\n",
    "from time import sleep\n",
    "for i in range(10):\n",
    "    show_images(noises[i % 2])\n",
    "    sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77414b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generation\n",
    "images = list()\n",
    "for current in noises:\n",
    "    for t in tqdm(ddim_scheduler.timesteps):\n",
    "        with torch.no_grad():\n",
    "            predicted_noise = model(current, t).sample\n",
    "            current = ddim_scheduler.step(predicted_noise, t, current).prev_sample\n",
    "    images.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show output\n",
    "euclidean = torch.norm((images[0]-images[1])).item() # calculate euclidean distance\n",
    "show_table([[tensor_as_html(images[0]), tensor_as_html(images[1]), tensor_as_html(torch.abs(images[0]-images[1]).mean(dim=1,keepdim=True).repeat(1,3,1,1))], [\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]])#display images, euclidean, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b57bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save input and output\n",
    "for i in range(len(noises)):\n",
    "    tensor_as_image(noises[i]).save(f\"../output/similar_ddim_noise_{i}.png\")\n",
    "    tensor_as_image(images[i]).save(f\"../output/similar_ddim_image_{i}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8368b2b5",
   "metadata": {},
   "source": [
    "## 2. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4244f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Letting the user choose a scaling factor\n",
    "noise_scaling_factor = user_input_noise_scaling_factor()     \n",
    "\n",
    "# prepare input\n",
    "noise = torch.randn((1, 3, image_size, image_size)) # sample random noise\n",
    "noises = [noise.clone() for _ in range(2)] # duplicate noise\n",
    "noises[1] = ((1-noise_scaling_factor**2)**0.5) * noises[1] + noise_scaling_factor * torch.randn((1, 3, image_size, image_size)) # change one of the full noise pictures by adding newly generated noise scaled down heavily\n",
    "euclidean = torch.norm((noises[0]-noises[1])).item() # calculate euclidean distance\n",
    "show_table([[tensor_as_html(noises[0]), tensor_as_html(noises[1]), tensor_as_html(torch.abs(noises[0]-noises[1]).mean(dim=1,keepdim=True).repeat(1,3,1,1))], [\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]])#display images, euclidean, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generation\n",
    "images = list()\n",
    "for current in noises:\n",
    "    for t in tqdm(ddim_scheduler.timesteps):\n",
    "        with torch.no_grad():\n",
    "            predicted_noise = model(current, t).sample\n",
    "            current = ddim_scheduler.step(predicted_noise, t, current).prev_sample\n",
    "    images.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a68684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show output\n",
    "euclidean = torch.norm((images[0]-images[1])).item() # calculate euclidean distance\n",
    "show_table([[tensor_as_html(images[0]), tensor_as_html(images[1]), tensor_as_html(torch.abs(images[0]-images[1]).mean(dim=1,keepdim=True).repeat(1,3,1,1))], [\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]])#display images, euclidean, heatmap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
