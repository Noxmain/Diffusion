{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe9f338",
   "metadata": {},
   "source": [
    "## DDIM with similar noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85bc3b7",
   "metadata": {},
   "source": [
    "In this notebook we will perform some experiments with Denoising Diffusion Implicit Models (DDIM). Unlike Denoising Diffusion Probabilistic Models (DDPM) DDIMs work deterministic, i.e. from one specific full noise picture it will always generate the same clear picture. Using a deterministic backwards process is essential here. If we used a probabilistic model, there would be a little noise added back into the picture after every backwards step, which would make the results differ heavily regardless of the starting point.\n",
    "\n",
    "We will do 2 Experimernts:\n",
    "\n",
    "1. Experiment (Patch condition): Change a small patch in the full noise picture and generate two clear images from it. You can choose the patch size and position yourself.\n",
    "2. Experiment (Full noise condition): Change the full noise images in a way that the mathematical distance between the two full noise images used as a starting point is very small. You can choose how much the noise is changed by choosing a value of noise_scaling_factor yourself.\n",
    "\n",
    "Each experiments will demonstrate different things:\n",
    "\n",
    "1. Experiment: Changing a small patch in the full noise picture will not only change that exact patch in the clear picture, but the whole picture. This shows that diffusion models captures dependecies between pixels by capturing the probablity distribtutions in the training dataset.\n",
    "2. Experiment: Changing the noise only a little only changes the resulting clear image a little.\n",
    "\n",
    "As you will see there is always the euclidean distance and heatmap displayed to give you an objective and visual measure where and how the images are changed. Feel free to try out different values in  both experiments. Some interesting questions to research could be:\n",
    "\n",
    "- Is there a correlation between the euclidean distance of the noise images and the euclidean distance of the clear images?\n",
    "- Given a similar euclidean distance of noise images in both experiments, is the result changed more strongly in the patch condition or the full noise condition?\n",
    "- In experiment 2: How much do you need to change the noise image to get substantially different results?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ce3a5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9bf74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd6639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import diffusers\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12007703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "model_id = \"google/ddpm-bedroom-256\" # \"google/ddpm-celebahq-256\"\n",
    "model = diffusers.UNet2DModel.from_pretrained(model_id)\n",
    "ddpm_scheduler = diffusers.DDPMScheduler.from_pretrained(model_id)\n",
    "ddpm_scheduler.set_timesteps(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input prepraration\n",
    "image_size = model.config.sample_size # get image size\n",
    "noise = torch.randn((1, 3, image_size, image_size)) # sample random noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b0ee7",
   "metadata": {},
   "source": [
    "## 1. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "ddim_scheduler = diffusers.DDIMScheduler.from_pretrained(model_id)\n",
    "ddim_scheduler.set_timesteps(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20faa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letting the user choose patchsize and position\n",
    "patch_size = None \n",
    "patch_position_x = None\n",
    "patch_position_y = None\n",
    "while patch_position_x == None or patch_position_x < 0 or patch_position_x > 256:\n",
    "    try:\n",
    "        patch_position_x = int(input(\"Please choose a x position for the patch between 0 and 256\"))\n",
    "    except ValueError:\n",
    "        print(\"Please insert an integer.\")\n",
    "while patch_position_y == None or patch_position_y < 0 or patch_position_y > 256:\n",
    "    try:\n",
    "        patch_position_y = int(input(\"Please choose a y position for the patch between 0 and 256\"))\n",
    "    except ValueError:\n",
    "        print(\"Please insert an integer.\")\n",
    "while patch_size == None or patch_position_x + patch_size > 256 or patch_position_y + patch_size > 256:\n",
    "    try:\n",
    "        patch_size = int(input(\"Please choose a patch size.\"))\n",
    "        if patch_position_x + patch_size > 256 or patch_position_y + patch_size > 256:\n",
    "            print(\"Patch size is to big. Please choose a smaller one.\")\n",
    "    except ValueError:\n",
    "        print(\"Please insert an integer.\")\n",
    "\n",
    "\n",
    "# prepare input\n",
    "noise = torch.randn((1, 3, image_size, image_size)) # sample random noise\n",
    "noises = [noise.clone() for _ in range(2)] # duplicate noise\n",
    "noises[1][:,:,patch_position_y:patch_position_y+patch_size,patch_position_x:patch_position_x+patch_size] = torch.randn((1, 3, patch_size, patch_size)) # change a small patch in one of the full noise pictures\n",
    "euclidean = torch.norm((noises[0]-noises[1])).item() # calculate euclidean distance\n",
    "show_table([[tensor_as_html(noises[0]), tensor_as_html(noises[1]), tensor_as_html(torch.abs(noises[0]-noises[1]).mean(dim=1,keepdim=True).repeat(1,3,1,1))], [\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]])#display images, euclidean, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6a5eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the images alternately\n",
    "from time import sleep\n",
    "for i in range(10):\n",
    "    show_images(noises[i % 2])\n",
    "    sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77414b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generation\n",
    "images = list()\n",
    "for current in noises:\n",
    "    for t in tqdm(ddim_scheduler.timesteps):\n",
    "        with torch.no_grad():\n",
    "            predicted_noise = model(current, t).sample\n",
    "            current = ddim_scheduler.step(predicted_noise, t, current).prev_sample\n",
    "    images.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show output\n",
    "euclidean = torch.norm((images[0]-images[1])).item() # calculate euclidean distance\n",
    "show_table([[tensor_as_html(images[0]), tensor_as_html(images[1]), tensor_as_html(torch.abs(images[0]-images[1]).mean(dim=1,keepdim=True).repeat(1,3,1,1))], [\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]])#display images, euclidean, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b57bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save input and output\n",
    "for i in range(len(noises)):\n",
    "    tensor_as_image(noises[i]).save(f\"../output/similar_ddim_noise_{i}.png\")\n",
    "    tensor_as_image(images[i]).save(f\"../output/similar_ddim_image_{i}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8368b2b5",
   "metadata": {},
   "source": [
    "## 2. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4244f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Letting the user choose a scaling factor\n",
    "noise_scaling_factor = None\n",
    "while noise_scaling_factor == None or noise_scaling_factor < 0.0 or noise_scaling_factor > 1.0:\n",
    "    try:\n",
    "        noise_scaling_factor = float(input(\"Please choose a noise scaling factor between 0.0 and 1.0\"))\n",
    "        if noise_scaling_factor < 0.0 or noise_scaling_factor > 1.0:\n",
    "            print(\"Please choose a value between 0.0 and 1.0\")\n",
    "    except ValueError:\n",
    "        print(\"Please insert a float.\")\n",
    "        \n",
    "\n",
    "\n",
    "# prepare input\n",
    "noise = torch.randn((1, 3, image_size, image_size)) # sample random noise\n",
    "noises = [noise.clone() for _ in range(2)] # duplicate noise\n",
    "noises[1] = ((1-noise_scaling_factor**2)**0.5) * noises[1] + noise_scaling_factor * torch.randn((1, 3, image_size, image_size)) # change one of the full noise pictures by adding newly generated noise scaled down heavily\n",
    "euclidean = torch.norm((noises[0]-noises[1])).item() # calculate euclidean distance\n",
    "show_table([[tensor_as_html(noises[0]), tensor_as_html(noises[1]), tensor_as_html(torch.abs(noises[0]-noises[1]).mean(dim=1,keepdim=True).repeat(1,3,1,1))], [\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]])#display images, euclidean, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output generation\n",
    "images = list()\n",
    "for current in noises:\n",
    "    for t in tqdm(ddim_scheduler.timesteps):\n",
    "        with torch.no_grad():\n",
    "            predicted_noise = model(current, t).sample\n",
    "            current = ddim_scheduler.step(predicted_noise, t, current).prev_sample\n",
    "    images.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a68684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show output\n",
    "euclidean = torch.norm((images[0]-images[1])).item() # calculate euclidean distance\n",
    "show_table([[tensor_as_html(images[0]), tensor_as_html(images[1]), tensor_as_html(torch.abs(images[0]-images[1]).mean(dim=1,keepdim=True).repeat(1,3,1,1))], [\"\", f\"Euclidean distance: {euclidean}\", \"Heatmap\"]])#display images, euclidean, heatmap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
