{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c90e5151",
   "metadata": {},
   "source": [
    "# Forward and Backward Process\n",
    "\n",
    "In this notebook, we explore what the decoder is capable of doing with:  \n",
    "1. A single image that has been noised at a specific step in the diffusion process\n",
    "2. A full sequence of progressively noised images across all diffusion steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e53fa7",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We begin by importing the necessary libraries and loading the pretrained diffusion model and scheduler.\n",
    "\n",
    "What you can change in the `src/config.yaml`:\n",
    "- You can select the model (and dataset) used by editing the `model` attribute\n",
    "- You can select the number of generation time steps by editing the `model.timesteps` attribute\n",
    "- You can select the specific step in the diffusion process by editing the `forward.timestep` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db40a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions\n",
    "import diffusers\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f587b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "model_id = functions.config(\"model\")\n",
    "model = diffusers.UNet2DModel.from_pretrained(model_id)\n",
    "scheduler = diffusers.DDIMScheduler.from_pretrained(model_id)\n",
    "scheduler.set_timesteps(functions.config(\"model.timesteps\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccf1049",
   "metadata": {},
   "source": [
    "## Denoising a noised image\n",
    "\n",
    "We start by loading an image and converting it into a tensor.  \n",
    "Then we simulate the forward prcess by adding noise to it at a specific timestep (forward_timestep_index).  \n",
    "Finally, we apply the decoder (reverse process) to try to reconstruct the original image from the noised version.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and transforming an image\n",
    "original_image = Image.open(\"../images/ddpm_9.png\")\n",
    "original_image = functions.image_as_tensor(original_image)\n",
    "image_size = model.config.sample_size # get image size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2a9726",
   "metadata": {},
   "source": [
    "We add noise to the image at the choses timestep in the diffusion process. Feel free to change the specific timestep by editing the `forward.timestep` attribute in the `src/config.yaml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1861234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward process\n",
    "noised_image = scheduler.add_noise(original_image, functions.generate_noise(image_size), scheduler.timesteps[functions.config(\"forward.timestep\")])\n",
    "functions.tensor_as_image(noised_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4694e03d",
   "metadata": {},
   "source": [
    "We iteratively apply the decoder to remove noise and reconstruct the image step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58836dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward process\n",
    "current = noised_image\n",
    "for t in tqdm(scheduler.timesteps[functions.config(\"forward.timestep\"):]):\n",
    "    with torch.no_grad():\n",
    "        predicted_noise = model(current, t).sample\n",
    "        current = scheduler.step(predicted_noise, t, current).prev_sample\n",
    "        functions.show_images(current)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5347eeba",
   "metadata": {},
   "source": [
    "We then compare the original image, the reconstructed image, and their difference to evaluate how well the model recovers lost information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df041c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare images\n",
    "functions.show_images(original_image, current, original_image - current)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c40b5",
   "metadata": {},
   "source": [
    "## Noise Accumulation and Decoder Output at Each Step\n",
    "\n",
    "The following code generates a large image that visualizes how information is gradually lost through the progressive addition of noise during the diffusion process. This cell may take a very long time to execute. If you do not want to execute the cell yourself, you can take a look at an example result in `images/process_ddpm_7.png`.\n",
    "\n",
    "- The first column shows the original image as processed by the encoder  \n",
    "- Each subsequent column displays the output of the decoder applied to increasingly noised versions of the image  \n",
    "- Each row corresponds to a specific step in the noise schedule: the further down, the more noise has been added before decoding. \n",
    "\n",
    "This visualization illustrates how, step by step, information degrades during the forward diffusion process (vertical axis). And how the decoder, step by step, reduces the noise to generate an image (horizontal axis). It also illustrates how the decoder's ability to recover the original image decreases as the input becomes more corrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93689a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup output image\n",
    "sampling_steps = len(scheduler.timesteps)\n",
    "output = Image.new(\"RGB\", (image_size * sampling_steps, image_size * sampling_steps), (255, 255, 255))\n",
    "output.paste(functions.tensor_as_image(original_image), (0, 0))\n",
    "\n",
    "# output generation\n",
    "with tqdm(total=sum(range(1, sampling_steps + 1))) as tqdm_bar:\n",
    "    # forward process loop (vertical axis)\n",
    "    for i in reversed(range(sampling_steps)):\n",
    "        # generate new noise and add it to the image\n",
    "        sampled_noise = functions.generate_noise(image_size)\n",
    "        current = scheduler.add_noise(original_image, sampled_noise, scheduler.timesteps[i])\n",
    "        output.paste(functions.tensor_as_image(current), (0, image_size * (sampling_steps - i)))\n",
    "        # reverse process loop (horizontal axis)\n",
    "        for j, t in enumerate(scheduler.timesteps[i:]):\n",
    "            # denoise the current image\n",
    "            with torch.no_grad():\n",
    "                predicted_noise = model(current, t).sample\n",
    "                current = scheduler.step(predicted_noise, t, current).prev_sample\n",
    "                output.paste(functions.tensor_as_image(current), (image_size * (j + 1), image_size * (sampling_steps - i)))\n",
    "            # update process bar\n",
    "            tqdm_bar.update(1)\n",
    "\n",
    "# save output image\n",
    "output.save(\"../output/process.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
